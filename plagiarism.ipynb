{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-Aware Plagiarism Advisory Tool\n",
    "Evelyn Yee (CS 329T Final Project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poster:\n",
    "![project poster](figures/poster.png)\n",
    "\n",
    "# Project Proposal\n",
    "- Domain: Education\n",
    "- Goal: Build a system to advise instructors and provide evidence for/against plagiarism in student works.\n",
    "    - Difficult false positives: critique, citing, reference\n",
    "    - Difficult false negatives: paraphrasing, summary, misquoting/misattribution\n",
    "- System:\n",
    "    1. **Retrieve** relevant documents from the corpus (e.g. vector search, string matching)\n",
    "    1. **Reason** over text+context documents with LLM (RAG)\n",
    "    1. **Identify** textual relationships\n",
    "        - Ground claims in passages from new document and context\n",
    "    1. Confidence estimation?\n",
    "- Trustworthiness Principles:\n",
    "    - **Grounding:** Each claim in the plagiarism analysis references specific features of the student document and at least one of the context documents.\n",
    "    - **Confidence:** Provide to users a report containing a) a combination of text heuristics (e.g. BLEU score) and b) an assessment from the LLM, ending with a single label of the text (\"plagiarized,\" \"related,\" or \"unrelated\")\n",
    "provide LLM CoT transcript/trace, so that users can understand and self-assess the label.\n",
    "\n",
    "- Data: [PlagBench](https://arxiv.org/abs/2406.16288v1) Eval Set (accessed directly from jooyoung lee, since the full dataset hasn't been publicly released yet)\n",
    "    - 405 plagiarism pairs\n",
    "        - 135 verbatim plagiarism\n",
    "        - 135 paraphrasing plagiarism\n",
    "        - 135 summarization plagiarism\n",
    "    - 405 non-plagiarism, related document pairs\n",
    "    \n",
    "    I have partitioned the dataset into a 70/15/15 train/validation/test split, with each split having the same proportion of each plagiarism label (i.e. 16.67% verbatim, 16.67% paraphrasing, 16.67% summary, 50% negative).\n",
    "\n",
    "TODO: PROMPT FOR A CONFIDENCE SCORE (COMPARE WITH LOGISTIC REGRESSION NUMERICAL CONFIDENCE) \n",
    "\n",
    "# Table of Contents\n",
    "- [Utilities](#utilities)\n",
    "    - [Global Imports](#global-imports)\n",
    "    - [Set up Snowflake](#set-up-snowflake-session)\n",
    "    - [Load Data](#load-data)\n",
    "    - [Evaluation Metrics](#evaluation-metrics)\n",
    "- [Our System](#our-system)\n",
    "    - [Prompts](#grounded-chain-of-thought-reasoning)\n",
    "    - [RAG Implementation](#generate-final-report)\n",
    "- [Baselines](#baselines)\n",
    "    - [Text Heuristics](#text-heuristics)\n",
    "    - [Parametric Knowledge + CoT](#parametric-knowledge--cot)\n",
    "    - [RAG + Direct Prompting](#rag--direct-answering)\n",
    "- [Evaluation](#evaluation)\n",
    "    - [Text Heuristics](#text-heuristics---eval)\n",
    "    - [Parametric Knowledge + CoT](#parametric-knowledge--cot---eval)\n",
    "    - [RAG + Direct Prompting](#rag--direct-answering---eval)\n",
    "    - [RAG + CoT (Our final model)](#rag--cot---eval)\n",
    "- [Results + Discussion](#results--discussion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities\n",
    "<a id='utilities'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install relevant packages\n",
    "# %pip install --upgrade trulens-core trulens-providers-openai trulens-providers-huggingface trulens-dashboard\n",
    "# %pip install --upgrade trulens-connectors-snowflake==1.2.2\n",
    "# %pip install --upgrade openai pandas tqdm snowflake scikit-learn nltk rouge-score numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages\n",
    "from datetime import timedelta\n",
    "import itertools\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from rouge_score.rouge_scorer import RougeScorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import threading\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "\n",
    "from trulens.providers.openai import OpenAI as OpenAI_tl\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "OPENAI_MODELS = ['gpt-4o-mini-2024-07-18']\n",
    "\n",
    "from snowflake.cortex import Complete\n",
    "SNOWFLAKE_MODELS = ['gemma-7b',\n",
    "'jamba-1.5-mini',\n",
    " 'jamba-1.5-large',\n",
    " 'jamba-instruct',\n",
    " 'llama2-70b-chat',\n",
    " 'llama3-8b',\n",
    " 'llama3-70b',\n",
    " 'llama3.1-8b',\n",
    " 'llama3.1-70b',\n",
    " 'llama3.1-405b',\n",
    " 'llama3.2-1b',\n",
    " 'llama3.2-3b',\n",
    " 'mistral-large',\n",
    " 'mistral-large2',\n",
    " 'mistral-7b',\n",
    " 'mixtral-8x7b',\n",
    " 'reka-core',\n",
    " 'reka-flash',\n",
    " 'snowflake-arctic']\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "import warnings\n",
    "def warn_on_retry(retry_state):\n",
    "    if retry_state.attempt_number > 1:\n",
    "        seconds_since_start = retry_state.upcoming_sleep or 0.0\n",
    "        # if retry_state.outcome.failed:\n",
    "        #     print(f\"Retrying due to: {retry_state.outcome.exception()}\")\n",
    "        print(f\"Trying...{retry_state.outcome}... Attempt {retry_state.attempt_number} after {seconds_since_start:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Snowflake Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials\n",
    "user = os.getenv('SNOWFLAKE_USER')\n",
    "password = os.getenv('SNOWFLAKE_PASS')\n",
    "connection_params = {\n",
    "    \"account\": \"TMB89584\",\n",
    "    \"user\": user,\n",
    "    \"password\": password,\n",
    "    \"role\": \"TRAINING_ROLE\",\n",
    "    \"database\": \"CHIPMUNK_DB\",\n",
    "    \"schema\": \"PLAGBENCH\",\n",
    "    \"warehouse\": \"ANIMAL_TASK_WH\",\n",
    "}\n",
    "\n",
    "# Create a Snowflake session\n",
    "snowpark_session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected_response\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpected_response\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# persist data in trulens database so we can fetch it from here in the future\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_ground_truth_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplagbench_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mground_truth_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msplit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m display(train\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/trulens/core/session.py:829\u001b[0m, in \u001b[0;36mTruSession.add_ground_truth_to_dataset\u001b[0;34m(self, dataset_name, ground_truth_df, dataset_metadata)\u001b[0m\n\u001b[1;32m    826\u001b[0m     buffer\u001b[38;5;241m.\u001b[39mappend(ground_truth)\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGROUND_TRUTHS_BATCH_SIZE:\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_insert_ground_truth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    830\u001b[0m         buffer\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m    832\u001b[0m \u001b[38;5;66;03m# remaining ground truths in the buffer\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/trulens/core/database/sqlalchemy.py:867\u001b[0m, in \u001b[0;36mSQLAlchemyDB.batch_insert_ground_truth\u001b[0;34m(self, ground_truths)\u001b[0m\n\u001b[1;32m    859\u001b[0m ground_truth_ids \u001b[38;5;241m=\u001b[39m [gt\u001b[38;5;241m.\u001b[39mground_truth_id \u001b[38;5;28;01mfor\u001b[39;00m gt \u001b[38;5;129;01min\u001b[39;00m ground_truths]\n\u001b[1;32m    861\u001b[0m \u001b[38;5;66;03m# Fetch existing GroundTruth records that match these ids in one query\u001b[39;00m\n\u001b[1;32m    862\u001b[0m existing_ground_truths \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    863\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGroundTruth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGroundTruth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mground_truth_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mground_truth_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 867\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m )\n\u001b[1;32m    870\u001b[0m existing_ground_truth_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    871\u001b[0m     gt\u001b[38;5;241m.\u001b[39mground_truth_id: gt \u001b[38;5;28;01mfor\u001b[39;00m gt \u001b[38;5;129;01min\u001b[39;00m existing_ground_truths\n\u001b[1;32m    872\u001b[0m }\n\u001b[1;32m    874\u001b[0m ground_truths_to_insert \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/orm/query.py:2673\u001b[0m, in \u001b[0;36mQuery.all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[_T]:\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the results represented by this :class:`_query.Query`\u001b[39;00m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;124;03m    as a list.\u001b[39;00m\n\u001b[1;32m   2654\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2671\u001b[0m \u001b[38;5;124;03m        :meth:`_engine.Result.scalars` - v2 comparable method.\u001b[39;00m\n\u001b[1;32m   2672\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mall()\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/orm/query.py:2827\u001b[0m, in \u001b[0;36mQuery._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2824\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params\n\u001b[1;32m   2826\u001b[0m statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statement_20()\n\u001b[0;32m-> 2827\u001b[0m result: Union[ScalarResult[_T], Result[_T]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_sa_orm_load_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_options\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2833\u001b[0m \u001b[38;5;66;03m# legacy: automatically set scalars, unique\u001b[39;00m\n\u001b[1;32m   2834\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_attributes\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_single_entity\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2362\u001b[0m, in \u001b[0;36mSession.execute\u001b[0;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event)\u001b[0m\n\u001b[1;32m   2301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\n\u001b[1;32m   2302\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2303\u001b[0m     statement: Executable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2309\u001b[0m     _add_event: Optional[Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Result[Any]:\n\u001b[1;32m   2311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Execute a SQL expression construct.\u001b[39;00m\n\u001b[1;32m   2312\u001b[0m \n\u001b[1;32m   2313\u001b[0m \u001b[38;5;124;03m    Returns a :class:`_engine.Result` object representing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2360\u001b[0m \n\u001b[1;32m   2361\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_internal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_parent_execute_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_parent_execute_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_add_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_add_event\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2247\u001b[0m, in \u001b[0;36mSession._execute_internal\u001b[0;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, _scalar_result)\u001b[0m\n\u001b[1;32m   2242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mscalar(\n\u001b[1;32m   2243\u001b[0m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options\u001b[38;5;241m=\u001b[39mexecution_options\n\u001b[1;32m   2244\u001b[0m     )\n\u001b[1;32m   2246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_state_cls:\n\u001b[0;32m-> 2247\u001b[0m     result: Result[Any] \u001b[38;5;241m=\u001b[39m \u001b[43mcompile_state_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morm_execute_statement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbind_arguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2255\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2256\u001b[0m     result \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   2257\u001b[0m         statement, params \u001b[38;5;129;01mor\u001b[39;00m {}, execution_options\u001b[38;5;241m=\u001b[39mexecution_options\n\u001b[1;32m   2258\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/orm/context.py:305\u001b[0m, in \u001b[0;36mAbstractORMCompileState.orm_execute_statement\u001b[0;34m(cls, session, statement, params, execution_options, bind_arguments, conn)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21morm_execute_statement\u001b[39m(\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m     conn,\n\u001b[1;32m    304\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Result:\n\u001b[0;32m--> 305\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39morm_setup_cursor_result(\n\u001b[1;32m    309\u001b[0m         session,\n\u001b[1;32m    310\u001b[0m         statement,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    314\u001b[0m         result,\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2358\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2356\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2357\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2358\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m   2359\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2360\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/sqlalchemy/engine/default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/cursor.py:989\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, _skip_upload_on_content_match, file_stream, num_statements, _dataframe_ast)\u001b[0m\n\u001b[1;32m    982\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    983\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery was rewritten: org=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, new=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m query\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[1;32m    985\u001b[0m         query1,\n\u001b[1;32m    986\u001b[0m     )\n\u001b[1;32m    987\u001b[0m     query \u001b[38;5;241m=\u001b[39m query1\n\u001b[0;32m--> 989\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sfqid \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    991\u001b[0m     ret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueryId\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    992\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ret \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueryId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ret[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    993\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    994\u001b[0m )\n\u001b[1;32m    995\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/cursor.py:700\u001b[0m, in \u001b[0;36mSnowflakeCursor._execute_helper\u001b[0;34m(self, query, timeout, statement_params, binding_params, binding_stage, is_internal, describe_only, _no_results, _is_put_get, _no_retry, dataframe_ast)\u001b[0m\n\u001b[1;32m    698\u001b[0m ret: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}}\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 700\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sequence_counter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbinding_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinding_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbinding_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinding_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_file_transfer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_file_transfer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_internal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_internal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescribe_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescribe_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_no_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_no_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    711\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_no_retry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_no_retry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    712\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreal_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataframe_ast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataframe_ast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/connection.py:1351\u001b[0m, in \u001b[0;36mSnowflakeConnection.cmd_query\u001b[0;34m(self, sql, sequence_counter, request_id, binding_params, binding_stage, is_file_transfer, statement_params, is_internal, describe_only, _no_results, _update_current_object, _no_retry, timeout, dataframe_ast)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1343\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msql=[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m], sequence_id=[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m], is_file_transfer=[\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1344\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_query_for_log(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlText\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m   1345\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequenceId\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1346\u001b[0m         is_file_transfer,\n\u001b[1;32m   1347\u001b[0m     )\n\u001b[1;32m   1349\u001b[0m url_parameters \u001b[38;5;241m=\u001b[39m {REQUEST_ID: request_id}\n\u001b[0;32m-> 1351\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/queries/v1/query-request?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43murlencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_parameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_no_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_no_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_include_retry_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_no_retry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_no_retry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1362\u001b[0m     ret \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: {}}\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/network.py:492\u001b[0m, in \u001b[0;36mSnowflakeRestful.request\u001b[0;34m(self, url, body, method, client, timeout, _no_results, _include_retry_params, _no_retry)\u001b[0m\n\u001b[1;32m    490\u001b[0m     headers[HTTP_HEADER_SERVICE_NAME] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mservice_name\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_no_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_no_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_include_retry_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_include_retry_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mno_retry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_no_retry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_request(\n\u001b[1;32m    504\u001b[0m         url,\n\u001b[1;32m    505\u001b[0m         headers,\n\u001b[1;32m    506\u001b[0m         token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken,\n\u001b[1;32m    507\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    508\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/network.py:740\u001b[0m, in \u001b[0;36mSnowflakeRestful._post_request\u001b[0;34m(self, url, headers, body, token, timeout, socket_timeout, _no_results, no_retry, _include_retry_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m     ret \u001b[38;5;241m=\u001b[39m probe_connection(full_url)\n\u001b[1;32m    738\u001b[0m     pprint(ret)\n\u001b[0;32m--> 740\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_retry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_retry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_include_retry_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_include_retry_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43msocket_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msocket_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mret[code] = \u001b[39m\u001b[38;5;132;01m{code}\u001b[39;00m\u001b[38;5;124m, after post request\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    753\u001b[0m         code\u001b[38;5;241m=\u001b[39m(ret\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    754\u001b[0m     )\n\u001b[1;32m    755\u001b[0m )\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m MASTER_TOKEN_EXPIRED_GS_CODE:\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/network.py:855\u001b[0m, in \u001b[0;36mSnowflakeRestful.fetch\u001b[0;34m(self, method, full_url, headers, data, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m retry_ctx\u001b[38;5;241m.\u001b[39mset_start_time()\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 855\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_exec_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/network.py:905\u001b[0m, in \u001b[0;36mSnowflakeRestful._request_exec_wrapper\u001b[0;34m(self, session, method, full_url, headers, data, retry_ctx, no_retry, token, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m raise_raw_http_failure \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise_raw_http_failure\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 905\u001b[0m     return_object \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_exec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfull_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraise_raw_http_failure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraise_raw_http_failure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m return_object\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/network.py:1072\u001b[0m, in \u001b[0;36mSnowflakeRestful._request_exec\u001b[0;34m(self, session, method, full_url, headers, data, token, catch_okta_unauthorized_error, is_raw_text, is_raw_binary, binary_data_handler, socket_timeout, is_okta_authentication, raise_raw_http_failure)\u001b[0m\n\u001b[1;32m   1068\u001b[0m download_start_time \u001b[38;5;241m=\u001b[39m get_time_millis()\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# socket timeout is constant. You should be able to receive\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m# the response within the time. If not, ConnectReadTimeout or\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# ReadTimeout is raised.\u001b[39;00m\n\u001b[0;32m-> 1072\u001b[0m raw_ret \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1073\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msocket_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_raw_binary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSnowflakeAuth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m download_end_time \u001b[38;5;241m=\u001b[39m get_time_millis()\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    729\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py:467\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    462\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/connectionpool.py:462\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 462\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/http/client.py:1395\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1394\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1395\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1396\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1397\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/http/client.py:325\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 325\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/http/client.py:286\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 286\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/contrib/pyopenssl.py:330\u001b[0m, in \u001b[0;36mWrappedSocket.recv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OpenSSL\u001b[38;5;241m.\u001b[39mSSL\u001b[38;5;241m.\u001b[39mWantReadError:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m timeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe read operation timed out\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:145\u001b[0m, in \u001b[0;36mwait_for_read\u001b[0;34m(sock, timeout)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait_for_read\u001b[39m(sock, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Waits for reading to be available on a given socket.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m    Returns True if the socket is readable, or False if the timeout expired.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwait_for_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:106\u001b[0m, in \u001b[0;36mpoll_wait_for_socket\u001b[0;34m(sock, read, write, timeout)\u001b[0m\n\u001b[1;32m    103\u001b[0m         t \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m poll_obj\u001b[38;5;241m.\u001b[39mpoll(t)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43m_retry_on_intr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo_poll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:43\u001b[0m, in \u001b[0;36m_retry_on_intr\u001b[0;34m(fn, timeout)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_retry_on_intr\u001b[39m(fn, timeout):\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/vendored/urllib3/util/wait.py:104\u001b[0m, in \u001b[0;36mpoll_wait_for_socket.<locals>.do_poll\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     t \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m poll_obj\u001b[38;5;241m.\u001b[39mpoll(t)\n",
      "File \u001b[0;32m~/.conda/envs/cs329t-hw2/lib/python3.11/site-packages/snowflake/connector/cursor.py:689\u001b[0m, in \u001b[0;36mSnowflakeCursor._execute_helper.<locals>.interrupt_handler\u001b[0;34m(*_)\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    687\u001b[0m             \u001b[38;5;66;03m# ignore failures\u001b[39;00m\n\u001b[1;32m    688\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create a snowflake cursor object\n",
    "cursor = snowflake_connection.cursor()\n",
    "\n",
    "# train\n",
    "# Define the SQL query to fetch the data\n",
    "train_query = \"SELECT * FROM CHIPMUNK_DB.PLAGBENCH.PLAGBENCH_TRAIN\"\n",
    "cursor.execute(train_query)\n",
    "train = cursor.fetch_pandas_all()\n",
    "train.rename(columns={'SUSP_DOC':'query', 'PLAGIARISM_TYPE':'expected_response'},\n",
    "             inplace=True)\n",
    "train['expected_response'] = train['expected_response'].fillna('NA')\n",
    "# persist data in trulens database so we can fetch it from here in the future\n",
    "session.add_ground_truth_to_dataset(\n",
    "    dataset_name=\"plagbench_train\",\n",
    "    ground_truth_df=train,\n",
    "    dataset_metadata={\"split\": \"train\"},\n",
    ")\n",
    "display(train.head())\n",
    "print(\"train size:\", train.shape)\n",
    "\n",
    "# test\n",
    "# Define the SQL query to fetch the data\n",
    "test_query = \"SELECT * FROM CHIPMUNK_DB.PLAGBENCH.PLAGBENCH_TEST\"\n",
    "cursor.execute(test_query)\n",
    "test = cursor.fetch_pandas_all()\n",
    "test.rename(columns={'SUSP_DOC':'query', 'PLAGIARISM_TYPE':'expected_response'},\n",
    "             inplace=True)\n",
    "test['expected_response'] = test['expected_response'].fillna('NA')\n",
    "# persist data in trulens database so we can fetch it from here in the future\n",
    "session.add_ground_truth_to_dataset(\n",
    "    dataset_name=\"plagbench_test\",\n",
    "    ground_truth_df=test,\n",
    "    dataset_metadata={\"split\": \"test\"},\n",
    ")\n",
    "display(test.head())\n",
    "print(\"test size:\", test.shape)\n",
    "\n",
    "# valid\n",
    "# Define the SQL query to fetch the data\n",
    "valid_query = \"SELECT * FROM CHIPMUNK_DB.PLAGBENCH.PLAGBENCH_VALID\"\n",
    "cursor.execute(valid_query)\n",
    "valid = cursor.fetch_pandas_all()\n",
    "valid.rename(columns={'SUSP_DOC':'query', 'PLAGIARISM_TYPE':'expected_response'},\n",
    "             inplace=True)\n",
    "valid['expected_response'] = valid['expected_response'].fillna('NA')\n",
    "# persist data in trulens database so we can fetch it from here in the future\n",
    "session.add_ground_truth_to_dataset(\n",
    "    dataset_name=\"plagbench_valid\",\n",
    "    ground_truth_df=valid,\n",
    "    dataset_metadata={\"split\": \"valid\"},\n",
    ")\n",
    "display(valid.head())\n",
    "print(\"valid size:\", valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source docs for retrieval\n",
    "ground_truth = pd.concat([train, test, valid])\n",
    "\n",
    "# check if source_docs table already in snowflake\n",
    "try:\n",
    "    source_docs = snowpark_session.read.table(\"CHIPMUNK_DB.PLAGBENCH.SOURCE_DOCS\")\n",
    "    source_docs_df = source_docs.to_pandas()\n",
    "except:\n",
    "    source_docs = ground_truth['SOURCE_DOC'].unique()\n",
    "    # write source_docs to snowflake\n",
    "    source_docs_df = pd.DataFrame(source_docs, columns=['content'])\n",
    "    source_docs_df['id'] = source_docs_df.index\n",
    "    snowpark_session.write_pandas(source_docs_df, table_name=\"SOURCE_DOCS\",\n",
    "                                  database=\"CHIPMUNK_DB\", schema='PLAGBENCH', auto_create_table=True)\n",
    "    source_docs = snowpark_session.read.table(\"CHIPMUNK_DB.PLAGBENCH.SOURCE_DOCS\")\n",
    "    source_docs_df = source_docs.to_pandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('marks_per_second', 5), ('seconds_per_period', 1), ('seconds_per_period_timedelta', datetime.timedelta(seconds=1)), ('mark_expirations', deque([])), ('max_marks', 60), ('last_mark', datetime.datetime(2024, 12, 2, 16, 59, 54, 486375)), ('lock', <unlocked _thread.lock object at 0x713de476d900>)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider = OpenAI_tl(model_engine=\"gpt-4o-mini-2024-07-18\",\n",
    "                     api_key=os.getenv('OPENAI_API_KEY'))\n",
    "provider.endpoint.pace.marks_per_second = 5\n",
    "provider.endpoint.pace.seconds_per_period = 1\n",
    "provider.endpoint.pace.seconds_per_period_timedelta = timedelta(seconds=1)\n",
    "provider.endpoint.pace.__dict__.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Trio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groundedness\n",
    "\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=1, max=10),before=warn_on_retry)\n",
    "def groundedness(target, context, output):\n",
    "    caller = provider.groundedness_measure_with_cot_reasons\n",
    "    context_str = ''\n",
    "    for i in range(len(context)):\n",
    "        context_str += f'SOURCE DOCUMENT {i+1}: {context[i]}\\n'\n",
    "    context_str += f'TARGET DOCUMENT: {target}'\n",
    "    criteria = f\"Your goal is to assess the groundedness of the provided STATEMENT \\\n",
    "in regard to the provided SOURCE DOCUMENTs and the TARGET DOCUMENT. \\\n",
    "Each STATEMENT should be substantiated by evidence from the TARGET DOCUMENT or at least one of the SOURCE DOCUMENTs. \\\n",
    "For each STATEMENT, think step by step and then score it with 1 if the claim is substantiated by the documents and 0 if it is not.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('error')\n",
    "        warnings.filterwarnings('ignore', category=UserWarning) # ignore issue with filtering trivial statements\n",
    "        try:\n",
    "            return caller(source=context_str, statement=output, criteria=criteria, min_score_val=0, max_score_val=1)\n",
    "        except Warning as e:\n",
    "            print('error in groundedness:',e)\n",
    "            return (np.nan,{'reasons': f'Warning: {e}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer Relevance\n",
    "\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=1, max=10),before=warn_on_retry)\n",
    "def a_relevance(prompt, output):\n",
    "    caller = provider.relevance_with_cot_reasons\n",
    "    criteria = f\"Your goal is to assess the relevance of the provided RESPONSE \\\n",
    "to the provided PROMPT, which is to identify whether plagiarism in the target (student) document. \\\n",
    "For each RESPONSE, think step by step and then score it with 1 if the claim is relevant to the task and 0 if it is not.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('error')\n",
    "        warnings.filterwarnings('ignore', category=UserWarning) # ignore issue with filtering trivial statements\n",
    "        try:\n",
    "            return caller(prompt, output, criteria=criteria, min_score_val=0, max_score_val=1)\n",
    "        except Warning as e:\n",
    "            print('error in answer relevance:',e)\n",
    "            return (np.nan,{'reason': f'Warning: {e}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context Relevance - not averaged\n",
    "\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=1, max=10),before=warn_on_retry)\n",
    "def c_relevance(target, context):\n",
    "    caller = provider.relevance_with_cot_reasons\n",
    "    criteria = f\"A student may have committed plagiarism, and your goal is to help identify it by filtering relevant documents. \\\n",
    "Your goal is to assess the relevance of each provided source documents, in the CONTEXT, to the provided student document, in the QUESTION. \\\n",
    "Think step by step, considering each source document separately, and if the context contains at least one document that is highly related to the target document, \\\n",
    "score the CONTEXT with 1. Otherwise, if none of the source documents in the CONTEXT are highly related to the student document, score the CONTEXT with a 0.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('error')\n",
    "        warnings.filterwarnings('ignore', category=UserWarning) # ignore issue with filtering trivial statements\n",
    "        try:\n",
    "            return caller(target, context, criteria=criteria, min_score_val=0, max_score_val=1)\n",
    "        except Warning as e:\n",
    "            print('error in context relevance:',e)\n",
    "            return (np.nan,{'reason': f'Warning: {e}'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification label metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In LLM Agreement, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      " In LLM Agreement, input response will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "def parse_label(output):\n",
    "    if 'LABEL:' in output:\n",
    "        return output.split('LABEL:')[1].strip()\n",
    "    return output[-15:]\n",
    "\n",
    "def accuracy_fine(df, expected='expected_response', output='output'):\n",
    "    return df.apply(lambda row: (row[expected] in parse_label(row[output])) if isinstance(row[expected], str) and isinstance(row[output], str) else np.nan, axis=1)\n",
    "\n",
    "def accuracy_coarse(df, label='LABEL', output='output'):\n",
    "    if df[label].dtype == bool:\n",
    "        yes=True\n",
    "        no=False\n",
    "    elif df[label].dtype == str:\n",
    "        yes='yes'\n",
    "        no='no'\n",
    "    else:\n",
    "        yes=1\n",
    "        no=0\n",
    "    def get_coarse(fine):\n",
    "        if 'NA' in parse_label(fine): # only look at the last 15 characters\n",
    "            return no\n",
    "        return yes\n",
    "    return df.apply(lambda row: (get_coarse(row[output]) == row[label]) if isinstance(row[output], str) else row[output] == yes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "\n",
    "def get_positivity(label_col):\n",
    "    if label_col.dtype == bool:\n",
    "        return lambda x: x\n",
    "    elif label_col.dtype == str:\n",
    "        return lambda x: x == 'True' or x == 'yes'\n",
    "    else:\n",
    "        return lambda x: x == 1\n",
    "\n",
    "\n",
    "# Precision\n",
    "def precision(df,\n",
    "              scores='accuracy_coarse', # binary accuracy metric, not raw output. use coarse labels by default\n",
    "              labels='LABEL'\n",
    "              ):\n",
    "    df = df.copy()\n",
    "    positivity = get_positivity(df[labels])\n",
    "    df['positive'] = df[labels].apply(positivity)\n",
    "    df['true_positive'] = (df['positive'] & df[scores])\n",
    "    tp = df['true_positive'].sum() or 0\n",
    "    df['false_positive'] = (~df['positive'] & ~df[scores])\n",
    "    fp = df['false_positive'].sum() or 0\n",
    "    if tp == 0 and fp == 0:\n",
    "        return np.nan\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "# Recall\n",
    "def recall(df,\n",
    "           scores='accuracy_coarse', # binary accuracy metric, not raw output. use coarse labels by default\n",
    "           labels='LABEL'\n",
    "           ):\n",
    "    df = df.copy()\n",
    "    positivity = get_positivity(df[labels])\n",
    "    df['positive'] = df[labels].apply(positivity)\n",
    "    df['true_positive'] = (df['positive'] & df[scores])\n",
    "    tp = df['true_positive'].sum() or 0\n",
    "    df['false_negative'] = (df['positive'] & ~df[scores])\n",
    "    fn = df['false_negative'].sum() or 0\n",
    "    if tp == 0 and fn == 0:\n",
    "        return np.nan\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "# F1\n",
    "def f1(df,\n",
    "       scores='accuracy_coarse', # binary accuracy metric, not raw output. use coarse labels by default\n",
    "       labels='LABEL'\n",
    "       ):\n",
    "    precision_score = precision(df, scores, labels) or 0\n",
    "    recall_score = recall(df, scores, labels) or 0\n",
    "    if precision_score == 0 and recall_score == 0:\n",
    "        return np.nan\n",
    "    return 2 * (precision_score * recall_score) / (precision_score + recall_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(output_col):\n",
    "    def parse_confidence(output):\n",
    "        if isinstance(output, str) and 'CONFIDENCE:' in output:\n",
    "            conf = output.split('CONFIDENCE:')[1].split(\"%\")[0]\n",
    "            # select numeric part of confidence, which may contain a single decimal point\n",
    "            conf = re.search(r'\\d+(\\.\\d+)?', conf).group()\n",
    "            return float(conf)\n",
    "        return np.nan\n",
    "    confidences = output_col.apply(parse_confidence)\n",
    "    if any(confidences.notna()):\n",
    "        return confidences.mean()\n",
    "    return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dashboard parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_stats(dashboard, grouping_cols, feedbacks, output_col='output'):\n",
    "    summary_stats = []\n",
    "    groups = dashboard.groupby(grouping_cols)\n",
    "    for group in groups:\n",
    "        group_name = group[0]\n",
    "        group_data = group[1]\n",
    "        group_id = zip(grouping_cols, group_name)\n",
    "        stats = {col:val for col,val in group_id}\n",
    "        stats['n']=len(group_data)\n",
    "\n",
    "        group_acc = group_data.assign(accuracy_fine=accuracy_fine(group_data, output=output_col),\n",
    "                                      accuracy_coarse=accuracy_coarse(group_data, output=output_col)\n",
    "                                      )\n",
    "        # summarize feedback scores\n",
    "        for feedback in feedbacks+['accuracy_fine', 'accuracy_coarse']:\n",
    "            stats[feedback] = group_acc[feedback].mean()\n",
    "        # summarize precision, recall\n",
    "        stats['precision'] = precision(group_acc)\n",
    "        stats['recall'] = recall(group_acc)\n",
    "        stats['f1'] = f1(group_acc)\n",
    "        stats['confidence'] = confidence(group_acc[output_col])\n",
    "        summary_stats.append(stats)\n",
    "    return pd.DataFrame(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our system\n",
    "<a id='ours'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grounded chain of Thought reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_prompt = \"\"\"You are a teacher's aid working to assist with grading of student submissions. To ensure academic honesty and fair grading, you need to evaluate whether student works plagiarize or not from one of the provided source texts.\n",
    "\n",
    "In this class, the teacher sorts assignments into four categories based on the level of plagiarism:\n",
    "- \"NA\": no plagiarism\n",
    "- \"verbatim\": when a student copies directly from the source text\n",
    "- \"paraphrasing\": when a student rephrases the source text\n",
    "- \"summary\": when a student summarizes the source text\n",
    "\n",
    "Think step by step, analyze the student submission, and finally respond with \"LABEL:\", followed by **the category label, as specified above** (one of \"NA\", \"verbatim\", \"paraphrasing\", \"summary\").\"\"\"\n",
    "\n",
    "\n",
    "less_brazen_prompt = \"\"\"You are a teacher's aid working to assist with grading of student submissions. To ensure academic honesty and fair grading, you need to evaluate whether student works plagiarize or not from one of the provided source texts.\n",
    "\n",
    "In this class, the teacher sorts assignments into four categories based on the level of plagiarism:\n",
    "- \"NA\": no plagiarism\n",
    "- \"verbatim\": when a student copies directly from the source text\n",
    "- \"paraphrasing\": when a student rephrases the source text\n",
    "- \"summary\": when a student summarizes the source text\n",
    "\n",
    "Many students do not plagiarize, so it is important to be thorough in your evaluation. If the student does make reference to one of the source texts, it is important to identify the type of reference made, as it may be benign and/or properly cited.\n",
    "\n",
    "As you evaluate the student's submission, consider your confidence in your assessment. If you are not confident in your assessment, state so, and do not falsely accuse students of plagiarism if you are no.\n",
    "\n",
    "Think step by step to analyze the student submission.\n",
    "Then, state your confidence as \"CONFIDENCE:\" followed by **a percentage** between 0% (not confident) and 100% (extremely confident).\n",
    "Finally, respond with \"LABEL:\", followed by **the category label, as specified above** (one of \"NA\", \"verbatim\", \"paraphrasing\", \"summary\").\"\"\"\n",
    "\n",
    "least_brazen_prompt = \"\"\"You are a teacher's aid working to assist with grading of student submissions. To ensure academic honesty and fair grading, you need to evaluate whether student works plagiarize from one of the provided source texts.\n",
    "\n",
    "In this class, the teacher sorts assignments into four categories based on the level of plagiarism:\n",
    "- \"NA\": no plagiarism. most students fall into this category.\n",
    "- \"verbatim\": when a student copies directly from the source text\n",
    "- \"paraphrasing\": when a student rephrases the source text\n",
    "- \"summary\": when a student summarizes the source text\n",
    "\n",
    "Many students do not plagiarize, so it is important to be thorough in your evaluation. If the student does make reference to one of the source texts, it is important to identify the type of reference made, as it may be benign and/or properly cited.\n",
    "**DO NOT FALSELY MARK BENIGN WORK AS PLAGIARISED.** It is better to be cautious and give the student the benefit of the doubt.\n",
    "\n",
    "As you evaluate the student's submission, consider your confidence in your assessment. If you are not confident in your assessment, state so, and do not falsely accuse students of plagiarism if you are not sure.\n",
    "\n",
    "Think step by step to analyze the student submission.\n",
    "Then, state your confidence as \"CONFIDENCE:\" followed by **a percentage** between 0% (not confident) and 100% (extremely confident).\n",
    "Finally, respond with \"LABEL:\", followed by **the category label, as specified above** (one of \"NA\", \"verbatim\", \"paraphrasing\", \"summary\").\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "MAX_LENGTH = 500\n",
    "\n",
    "\n",
    "class Plagiarism_Classifier:\n",
    "\n",
    "    def __init__(self, embed_model, top_k,\n",
    "                 llm, instruction_prompt,\n",
    "                 f_ground=False, f_a_rel=False, f_c_rel=False,\n",
    "                 verbose=False):\n",
    "        self.embed_model = embed_model\n",
    "        self.top_k = top_k\n",
    "        self.llm = llm\n",
    "        assert self.llm in SNOWFLAKE_MODELS or self.llm in OPENAI_MODELS, f\"Model {self.llm} not recognized\"\n",
    "\n",
    "        self.instruction_prompt = instruction_prompt\n",
    "        self.f_ground = f_ground\n",
    "        self.f_a_rel = f_a_rel\n",
    "        self.f_c_rel = f_c_rel\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def train(self, source_docs_df):\n",
    "        # set up vector store\n",
    "        print('Setting up vector store')\n",
    "        self.chroma_client = chromadb.EphemeralClient()\n",
    "        if self.embed_model != 'default':\n",
    "            embedding_function = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                    api_key=os.getenv('OPENAI_API_KEY'),\n",
    "                    model_name=self.embed_model\n",
    "                )\n",
    "            self.vector_store = self.chroma_client.get_or_create_collection(name=f\"source_docs_{self.embed_model}\",\n",
    "                                                                            embedding_function=embedding_function)\n",
    "        else:\n",
    "            self.vector_store = self.chroma_client.get_or_create_collection(name=f\"source_docs_{self.embed_model}\")\n",
    "        ids = self.vector_store.get(include=[\"documents\"])[\"ids\"]\n",
    "        new_docs = source_docs_df[~source_docs_df['id'].astype(str).isin(ids)]\n",
    "        if len(new_docs) > 0:\n",
    "            print(f'Adding {len(new_docs)} source docs to vector store')\n",
    "            self.vector_store.add(ids = new_docs['id'].astype(str).to_list(),documents= new_docs['content'].to_list())\n",
    "\n",
    "    def render_prompt(self, suspect, context = []):\n",
    "        prompt = self.instruction_prompt\n",
    "        if len(context) > 0:\n",
    "            prompt += \"RELEVANT DOCUMENTS: \" + \"\\\"\\n\\t\\\"\".join(context)[1:]+\"\\\"\"\n",
    "        prompt += \"STUDENT SUBMISSION: \" + suspect\n",
    "        return [{\"role\":\"user\",\"content\": prompt}]\n",
    "\n",
    "    @instrument\n",
    "    def retrieve(self, query):\n",
    "        results = self.vector_store.query(query_texts=query, n_results=self.top_k)\n",
    "        return [doc for sublist in results['documents'] for doc in sublist]\n",
    "\n",
    "    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=1, max=10),before=warn_on_retry)\n",
    "    def generate(self, messages):\n",
    "        if self.llm in SNOWFLAKE_MODELS:\n",
    "            response = json.loads(Complete(self.llm, messages,\n",
    "                              session=snowpark_session,\n",
    "                              options={'temperature':0, 'max_tokens':MAX_LENGTH}))\n",
    "            response_text = response['choices'][0]['messages'].strip()\n",
    "            return response_text\n",
    "        else:\n",
    "            response = openai_client.chat.completions.create(messages=messages,\n",
    "            model=self.llm,\n",
    "            temperature = 0,\n",
    "            max_tokens= MAX_LENGTH)\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            return response_text\n",
    "\n",
    "    @instrument\n",
    "    def classify_plagiarism(self, suspect):\n",
    "        feedback = {}\n",
    "        chunks = self.retrieve(suspect)\n",
    "        if self.verbose:\n",
    "            print('retrieved docs')\n",
    "            print(chunks)\n",
    "        assert len(chunks) > 0, \"No relevant documents found\"\n",
    "        if self.f_c_rel and len(chunks) > 0:\n",
    "            if self.verbose: print('checking context relevance')\n",
    "            feedback.update({'context': chunks})\n",
    "            cr_score, cr_reason  = c_relevance(suspect, chunks)\n",
    "            feedback.update({'context relevance': cr_score, 'context relevance reason': (cr_reason['reason'] if 'reason' in cr_reason\n",
    "                                                                                         else cr_reason['reasons'] if 'reasons' in cr_reason\n",
    "                                                                                         else cr_reason)})\n",
    "        rendered_prompt = self.render_prompt(suspect, chunks)\n",
    "        if self.verbose: print('rendered prompt')\n",
    "        output = self.generate(rendered_prompt)\n",
    "        if self.verbose:\n",
    "            print('generated output')\n",
    "            print(output)\n",
    "        if self.f_ground:\n",
    "            if self.verbose: print('checking groundedness')\n",
    "            g_score, g_reason = groundedness(suspect, chunks, output)\n",
    "            feedback.update({'groundedness': g_score, 'groundedness reason': g_reason['reasons']})\n",
    "        if self.f_a_rel:\n",
    "            if self.verbose: print('checking answer relevance')\n",
    "            prompt_no_context = self.render_prompt(suspect)\n",
    "            a_score, a_reason = a_relevance(prompt_no_context, output)\n",
    "            feedback.update({'answer relevance': a_score, 'answer relevance reason': (a_reason['reason'] if 'reason' in a_reason\n",
    "                                                                                         else a_reason['reasons'] if 'reasons' in a_reason\n",
    "                                                                                         else a_reason)})\n",
    "        return output, feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual eval function\n",
    "TIMEOUT = 60 # give each question 60 seconds to complete\n",
    "\n",
    "def eval(embed_model, top_k,\n",
    "         #  chunk_size,\n",
    "         llm, instruction_prompt, data, model_id='', split='test', threads = 10, classifier=None, dashboard = [], verbose=False):\n",
    "\n",
    "    metadata={  # add any additional config hyperparameters below\n",
    "            'llm':llm,\n",
    "            'embed_model':embed_model,\n",
    "            'top_k':top_k,\n",
    "            'prompt':instruction_prompt,\n",
    "            'prompt style': ('less brazen' if instruction_prompt == less_brazen_prompt\n",
    "                                else 'least brazen' if instruction_prompt == least_brazen_prompt\n",
    "                             else 'original'),\n",
    "            # 'chunk_size':chunk_size,\n",
    "            'split': split,\n",
    "            'timestamp': pd.Timestamp.now()\n",
    "            }\n",
    "    if model_id:\n",
    "        metadata['model_id'] = model_id\n",
    "    if classifier is None:\n",
    "        plagiarism_classifier = Plagiarism_Classifier(embed_model, top_k,\n",
    "                                                #   chunk_size,\n",
    "                                                  llm, instruction_prompt,\n",
    "                                                  f_ground=True, f_a_rel=True, f_c_rel=True, verbose=verbose)\n",
    "        plagiarism_classifier.train(source_docs_df)\n",
    "    else:\n",
    "        plagiarism_classifier = classifier\n",
    "    if threads > 1: # multi-threaded\n",
    "\n",
    "        batch_size = (len(data)+threads-1) // threads\n",
    "        batches = [data.iloc[i*batch_size:(i+1)*batch_size] for i in range(threads)]\n",
    "        # split data into even batches\n",
    "\n",
    "        thread_list = []\n",
    "        for i, batch in enumerate(batches):\n",
    "            if len(batch) > 0: # do not create threads for empty batches\n",
    "                thread_list.append((threading.Thread(target=eval,\n",
    "                                                        args=(embed_model, top_k,\n",
    "                                                                #  chunk_size,\n",
    "                                                                llm, instruction_prompt, batch),\n",
    "                                                        kwargs={'split':split, 'threads':1,\n",
    "                                                                'model_id':model_id,\n",
    "                                                                'classifier':plagiarism_classifier, 'dashboard':dashboard}),\n",
    "                                    batch)) # store results for the thread by mutating these lists\n",
    "\n",
    "                print(f\"{thread_list[-1][0].name}: {len(batch)} question{'' if len(batch) == 1 else 's'}\")\n",
    "        # Start every thread\n",
    "        for thread, batch in thread_list:\n",
    "            thread.start()\n",
    "        # Wait for every thread to end\n",
    "        for thread, batch in thread_list:\n",
    "            thread.join(timeout=TIMEOUT*len(batch)) # allow timeout per question.\n",
    "            if thread.is_alive():\n",
    "                print(f\"{thread.name} timed out.\")\n",
    "                continue # allow timed-out threads to run until all others have been checked\n",
    "            # print(f\"{thread.name} finished.\")\n",
    "        for thread, batch in thread_list: # final check for straggler threads\n",
    "            if thread.is_alive():\n",
    "                print(f\"FINAL CHECK - {thread.name} timed out.\")\n",
    "        print(\"All threads finished\")\n",
    "    else: # single thread\n",
    "        for i, row in tqdm(data.iterrows()):\n",
    "            # with recorder as recording:\n",
    "            dash_row = metadata.copy()\n",
    "            label, feedback = plagiarism_classifier.classify_plagiarism(row['query'])\n",
    "            dash_row.update({'query':row['query'], 'expected_response':row['expected_response'], 'LABEL':row['LABEL'],'output':label})\n",
    "            dash_row.update(feedback)\n",
    "            dashboard.append(dash_row)\n",
    "    return pd.DataFrame(dashboard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dashboard.csv exists, load\n",
    "if os.path.exists('dashboard.csv'):\n",
    "    mega_dashboard = pd.read_csv('dashboard.csv')\n",
    "else:\n",
    "    mega_dashboard = pd.DataFrame()\n",
    "\n",
    "if 'prompt' not in mega_dashboard.columns:\n",
    "    mega_dashboard['prompt'] = instruction_prompt\n",
    "    mega_dashboard['prompt style'] = 'original'\n",
    "else:\n",
    "    mega_dashboard['prompt'] = mega_dashboard['prompt'].fillna(instruction_prompt)\n",
    "    mega_dashboard['prompt style'] = mega_dashboard['prompt'].apply(lambda x: 'less brazen' if x == less_brazen_prompt\n",
    "                                else 'least brazen' if x == least_brazen_prompt\n",
    "                             else 'original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_models = [ # embedding models\n",
    "                # \"snowflake-arctic-embed-m\",\n",
    "                # \"e5-base-v2\"\n",
    "                'default',\n",
    "                'text-embedding-3-small',\n",
    "                # 'text-embedding-3-large',\n",
    "                # 'text-embedding-ada-002',\n",
    "                # 'babbage-002'\n",
    "                ]\n",
    "top_ks = [\n",
    "          1,\n",
    "          3,\n",
    "          # 5,\n",
    "          10\n",
    "          ]\n",
    "\n",
    "llms = [ # text generation models\n",
    "    # \"snowflake-arctic\",\n",
    "    # \"llama3.1-70b\",\n",
    "    # \"mixtral-8x7b\",\n",
    "    # \"mistral-7b\",\n",
    "    # \"llama3.1-8b\"\n",
    "    'gpt-4o-mini-2024-07-18',\n",
    "]\n",
    "\n",
    "prompts = [\n",
    "           instruction_prompt,\n",
    "        #    less_brazen_prompt\n",
    "            #   least_brazen_prompt\n",
    "           ]\n",
    "\n",
    "if mega_dashboard.shape[0] < valid.shape[0]*len(embed_models)*len(top_ks)*len(llms)*len(prompts):\n",
    "    for embed_model, top_k, llm, prompt in tqdm(itertools.product(\n",
    "        embed_models,\n",
    "        top_ks,\n",
    "        llms,\n",
    "        prompts\n",
    "        )):\n",
    "        print(f\"Embedding model: {embed_model}, Top K: {top_k}, LLM: {llm}, Prompt style: {'less brazen' if prompt == less_brazen_prompt else 'original'}\")\n",
    "        data = valid.iloc[:]\n",
    "        hyper_dashboard = eval(embed_model, top_k, llm, prompt, data, split='valid',threads=30,dashboard=[])\n",
    "        mega_dashboard = pd.concat([mega_dashboard, hyper_dashboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_dashboard['expected_response'] = mega_dashboard['expected_response'].fillna('NA')\n",
    "mega_dashboard.to_csv('dashboard.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt style</th>\n",
       "      <th>n</th>\n",
       "      <th>context relevance</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>answer relevance</th>\n",
       "      <th>accuracy_fine</th>\n",
       "      <th>accuracy_coarse</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>least brazen</td>\n",
       "      <td>736</td>\n",
       "      <td>0.854620</td>\n",
       "      <td>0.660587</td>\n",
       "      <td>0.987772</td>\n",
       "      <td>0.535326</td>\n",
       "      <td>0.839674</td>\n",
       "      <td>0.747863</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855746</td>\n",
       "      <td>90.815217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>less brazen</td>\n",
       "      <td>729</td>\n",
       "      <td>0.857339</td>\n",
       "      <td>0.685327</td>\n",
       "      <td>0.998628</td>\n",
       "      <td>0.508916</td>\n",
       "      <td>0.813443</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836145</td>\n",
       "      <td>91.469780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>original</td>\n",
       "      <td>546</td>\n",
       "      <td>0.864469</td>\n",
       "      <td>0.738764</td>\n",
       "      <td>0.919414</td>\n",
       "      <td>0.470696</td>\n",
       "      <td>0.811355</td>\n",
       "      <td>0.741206</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.851371</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prompt style    n  context relevance  groundedness  answer relevance  \\\n",
       "0  least brazen  736           0.854620      0.660587          0.987772   \n",
       "1   less brazen  729           0.857339      0.685327          0.998628   \n",
       "2      original  546           0.864469      0.738764          0.919414   \n",
       "\n",
       "   accuracy_fine  accuracy_coarse  precision  recall        f1  confidence  \n",
       "0       0.535326         0.839674   0.747863     1.0  0.855746   90.815217  \n",
       "1       0.508916         0.813443   0.718427     1.0  0.836145   91.469780  \n",
       "2       0.470696         0.811355   0.741206     1.0  0.851371         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hyper = get_summary_stats(mega_dashboard, ['prompt style'], ['context relevance', 'groundedness', 'answer relevance'])\n",
    "display(hyper.sort_values('accuracy_coarse', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "![embed results](figures/embed_model_validation.png)\n",
    "\n",
    "![top-k results](figures/top_k_validation.png)\n",
    "\n",
    "![top-k results](figures/prompt_validation.png)\n",
    "\n",
    "**Looking at the ground truth labels:**\n",
    "\n",
    "On this validation set, we got **100% recall** on the coarse labels (binary plagiarism/no plagiarism) for all combinations of retriever settings and prompts that we tried. This indicates that the generator model didn't miss any plagiarism cases (i.e. no false negatives). As a result, the overall performance (measured via accuracy or f1) is really just dependent on the amount the model over-triggers. In this regard, we had the best performance for the retriever with the `text-embedding-3-small` embeddings, retrieving the top 3 sources for each suspect document, and with the most cautious prompt. \n",
    "\n",
    "verall, it seems that the **`text-embedding-3-small` embedding model** is slightly better for this task than the default chromadb embedding model, and the system does better (finds makes spurious plagiarism claims) when **retrieving fewer documents**. The fewer documents point makes sense; since we have the actual ground truth source document for each query in our retrieval corpus, the additional documents may just contribute noise.\n",
    "\n",
    "**Looking at the RAG evaluation metrics:**\n",
    "- **context relevance** decreases as the number of retrieved doocuments increases. This makes sense because, again, we have access to the single ground truth relevant document.\n",
    "- **groundedness** increases as the number of retrieved documents increases. I think this may be because the larger context leads to a longer prompt and a longer chain of thought, providing more opportunities to ground the answer in both the context and the query.\\\n",
    "- **answer relevance** stays about the same as the number of retrieved documents increases. This makes sense, because the llm that generates the final answer does not depend on the retriever.\n",
    "\n",
    "\n",
    "**Looking at the Confidence:**\n",
    "The reported confidence did not seem to depend strongly on the prompt or retriever settings. I suspect this may have more to do with the generator LLM, which I did not tune over for cost and practicality rasons.\n",
    "\n",
    "**For my final evaluation**, I will use the `text-embedding-3-small` embedding model, with 3 documents retrieved and the most cautious prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "<a id='baselines'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'train_heuristics.csv' in os.listdir():\n",
    "    train_heuristics = pd.read_csv('train_heuristics.csv').fillna('NA')\n",
    "else:\n",
    "    train_heuristics = train.copy()\n",
    "if 'valid_heuristics.csv' in os.listdir():\n",
    "    valid_heuristics = pd.read_csv('valid_heuristics.csv').fillna('NA')\n",
    "else:\n",
    "    train_heuristics = train.copy()\n",
    "if 'test_heuristics.csv' in os.listdir():\n",
    "    test_heuristics = pd.read_csv('test_heuristics.csv').fillna('NA')\n",
    "else:\n",
    "    train_heuristics = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU score\n",
    "def bleu_score(suspect, source_docs):\n",
    "    \"\"\"Return the BLEU score of the suspect text compared to all of the source documents together.\"\"\"\n",
    "    suspect = nltk.word_tokenize(suspect)\n",
    "    smoother = nltk.translate.bleu_score.SmoothingFunction().method1 # smoothing function, if no occurrences of n-grams\n",
    "    return nltk.translate.bleu([nltk.word_tokenize(doc) for doc in source_docs], suspect, smoothing_function=smoother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUGE score\n",
    "def rouge_score(suspect, source_docs):\n",
    "    \"\"\"Return the maximum ROUGE-L score of the suspect text compared to each of the source documents separately.\"\"\"\n",
    "    rouge = RougeScorer(rouge_types=['rougeL'], use_stemmer=True)\n",
    "    return rouge.score_multi(source_docs, suspect)['rougeL'].fmeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-calculate BLEU and ROUGE scores for each dataset, for faster iterating on regression hyperparameters\n",
    "for df,split in [(train_heuristics,'train'), (valid_heuristics,'valid'), (test_heuristics,'test')]:\n",
    "    updated = False\n",
    "    if 'bleu' not in df.columns:\n",
    "        df['bleu'] = df['query'].progress_apply(lambda x: bleu_score(x, source_docs_df['content']))\n",
    "        updated = True\n",
    "    if 'rouge' not in df.columns:\n",
    "        df['rouge'] = df['query'].progress_apply(lambda x: rouge_score(x, source_docs_df['content']))\n",
    "        updated = True\n",
    "    if updated:\n",
    "        df.to_csv(f\"{split}_heuristics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plagiarism_Classifier_Heuristic:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.regressor = LogisticRegression()\n",
    "\n",
    "    def train(self, X,y):\n",
    "        self.regressor.fit(X,y)\n",
    "\n",
    "    @instrument\n",
    "    def classify_plagiarism(self, query, bleu, rouge):\n",
    "        label = self.regressor.predict(np.array([bleu, rouge]).reshape(1, -1))\n",
    "        return label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual eval function\n",
    "TIMEOUT = 60 # give each question 60 seconds to complete\n",
    "\n",
    "def heuristic_eval(granularity, data, model_id='', split='test', threads = 10, classifier=None, dashboard = []):\n",
    "    if model_id == '':\n",
    "        metadata={  # add any additional config hyperparameters below\n",
    "            'training granularity': granularity,\n",
    "                'split': split\n",
    "                }\n",
    "    else:\n",
    "        metadata={  # add any additional config hyperparameters below\n",
    "            'training granularity': granularity,\n",
    "                'split': split,\n",
    "                'model_id': model_id\n",
    "                }\n",
    "    if classifier is None:\n",
    "        plagiarism_classifier = Plagiarism_Classifier_Heuristic()\n",
    "        if granularity == 'fine':\n",
    "            train_label = 'expected_response'\n",
    "        else:\n",
    "            train_label = 'LABEL'\n",
    "        plagiarism_classifier.train(train_heuristics[['bleu', 'rouge']].values, train_heuristics[train_label])\n",
    "    else:\n",
    "        plagiarism_classifier = classifier\n",
    "\n",
    "    if threads > 1: # multi-threaded\n",
    "\n",
    "        batch_size = (len(data)+threads-1) // threads\n",
    "        batches = [data.iloc[i*batch_size:(i+1)*batch_size] for i in range(threads)]\n",
    "        # split data into even batches\n",
    "\n",
    "        thread_list = []\n",
    "        for i, batch in enumerate(batches):\n",
    "            if len(batch) > 0: # do not create threads for empty batches\n",
    "                thread_list.append((threading.Thread(target=eval,\n",
    "                                                        args=(embed_model, top_k,\n",
    "                                                                llm, instruction_prompt, batch),\n",
    "                                                        kwargs={'split':split, 'threads':1,\n",
    "                                                                'classifier':plagiarism_classifier, 'dashboard':dashboard}),\n",
    "                                    batch)) # store results for the thread by mutating these lists\n",
    "\n",
    "                print(f\"{thread_list[-1][0].name}: {len(batch)} question{'' if len(batch) == 1 else 's'}\")\n",
    "        # Start every thread\n",
    "        for thread, batch in thread_list:\n",
    "            thread.start()\n",
    "        # Wait for every thread to end\n",
    "        for thread, batch in thread_list:\n",
    "            thread.join(timeout=TIMEOUT*len(batch)) # allow timeout per question.\n",
    "            if thread.is_alive():\n",
    "                print(f\"{thread.name} timed out.\")\n",
    "                continue # allow timed-out threads to run until all others have been checked\n",
    "            print(f\"{thread.name} finished.\")\n",
    "        for thread, batch in thread_list: # final check for straggler threads\n",
    "            if thread.is_alive():\n",
    "                print(f\"FINAL CHECK - {thread.name} timed out.\")\n",
    "        print(\"All threads finished\")\n",
    "    else: # single thread\n",
    "        for i, row in tqdm(data.iterrows()):\n",
    "            dash_row = metadata.copy()\n",
    "            if 'bleu' not in row:\n",
    "                bleu = bleu_score(row['query'], source_docs_df['content'])\n",
    "            else:\n",
    "                bleu = row['bleu']\n",
    "            if 'rouge' not in row:\n",
    "                rouge = rouge_score(row['query'], source_docs_df['content'])\n",
    "            else:\n",
    "                rouge = row['rouge']\n",
    "            label = plagiarism_classifier.classify_plagiarism(row['query'], bleu, rouge)\n",
    "            dash_row.update({'query':row['query'], 'expected_response':row['expected_response'], 'LABEL':row['LABEL'],'output':label})\n",
    "            dashboard.append(dash_row)\n",
    "    return pd.DataFrame(dashboard)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'heuristic_dashboard.csv' in os.listdir():\n",
    "    heuristic_dashboard = pd.read_csv('heuristic_dashboard.csv')\n",
    "else:\n",
    "    heuristic_dashboard = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granularity: fine\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c838433c08f14fbe9b77bfb43054dcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granularity: coarse\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "243cb90c583d4790b98ccb1cbbc06398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for granularity in ['fine', 'coarse']:\n",
    "    print(f\"Granularity: {granularity}\")\n",
    "    hyper_dashboard = heuristic_eval(granularity, valid_heuristics.iloc[:], split='valid',threads=1,dashboard=[])\n",
    "    heuristic_dashboard = pd.concat([heuristic_dashboard, hyper_dashboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training granularity</th>\n",
       "      <th>split</th>\n",
       "      <th>n</th>\n",
       "      <th>accuracy_fine</th>\n",
       "      <th>accuracy_coarse</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fine</td>\n",
       "      <td>valid</td>\n",
       "      <td>122</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.893443</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.873786</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coarse</td>\n",
       "      <td>valid</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.434426</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.605714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  training granularity  split    n  accuracy_fine  accuracy_coarse  precision  \\\n",
       "1                 fine  valid  122       0.844262         0.893443   1.000000   \n",
       "0               coarse  valid  122            NaN         0.434426   0.452991   \n",
       "\n",
       "     recall        f1  confidence  \n",
       "1  0.775862  0.873786         NaN  \n",
       "0  0.913793  0.605714         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fine\n",
      "coarse\n"
     ]
    }
   ],
   "source": [
    "hyper = get_summary_stats(heuristic_dashboard, ['training granularity', 'split'], [])\n",
    "display(hyper.sort_values('accuracy_coarse', ascending=False))\n",
    "print('\\n'.join(hyper.sort_values('accuracy_coarse', ascending=False)['training granularity'].astype(str).values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Granularity:\n",
    "![validation results](figures/heuristic-validation.png)\n",
    "\n",
    "Training the logistic regression model to predict the coarse labels (yes/no plagiarism) seems to have better recall (missed fewer cases of actual plagiarism) but much worse precision (more cases of false triggers on non-plagiarized works) when compared to training to predict the fine labels (verbatim/paraphrasing/summary/no plagiarism). I hypothesize that this might be caused by some core differences in the n-gram appearance of different types of plagiarism (e.g. paraphrasing and summarizing plagiarism look similar to non-plagiarism, so the coarse model was over-predicting plagiarism in these cases).\n",
    "\n",
    "I'm going to keep the **fine-label predictor** as my baseline for this project, because the results are better, more directly comparable to the full LLM system, and more informative to instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric knowledge + CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametric_prompt = \"\"\"You are a teacher's aid working to assist with grading of student submissions. To ensure academic honesty and fair grading, you need to evaluate whether student works plagiarize or not.\n",
    "\n",
    "In this class, the teacher sorts assignments into four categories based on the level of plagiarism:\n",
    "- \"NA\": no plagiarism\n",
    "- \"verbatim\": when a student copies directly from the source text\n",
    "- \"paraphrasing\": when a student rephrases the source text\n",
    "- \"summary\": when a student summarizes the source text\n",
    "\n",
    "Think step by step, analyze the student submission, and finally respond with \"LABEL:\", followed by **the category label, as specified above** (one of \"NA\", \"verbatim\", \"paraphrasing\", \"summary\").\"\"\"\n",
    "\n",
    "least_brazen_parametric_prompt = \"\"\"You are a teacher's aid working to assist with grading of student submissions. To ensure academic honesty and fair grading, you need to evaluate whether student works plagiarize.\n",
    "\n",
    "In this class, the teacher sorts assignments into four categories based on the level of plagiarism:\n",
    "- \"NA\": no plagiarism. most students fall into this category.\n",
    "- \"verbatim\": when a student copies directly from the source text\n",
    "- \"paraphrasing\": when a student rephrases the source text\n",
    "- \"summary\": when a student summarizes the source text\n",
    "\n",
    "Many students do not plagiarize, so it is important to be thorough in your evaluation.\n",
    "**DO NOT FALSELY MARK BENIGN WORK AS PLAGIARISED.** It is better to be cautious and give the student the benefit of the doubt.\n",
    "\n",
    "As you evaluate the student's submission, consider your confidence in your assessment. If you are not confident in your assessment, state so, and do not falsely accuse students of plagiarism if you are not sure.\n",
    "\n",
    "Think step by step to analyze the student submission.\n",
    "Then, state your confidence as \"CONFIDENCE:\" followed by **a percentage** between 0% (not confident) and 100% (extremely confident).\n",
    "Finally, respond with \"LABEL:\", followed by **the category label, as specified above** (one of \"NA\", \"verbatim\", \"paraphrasing\", \"summary\").\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 500\n",
    "\n",
    "\n",
    "class Plagiarism_Classifier_Parametric:\n",
    "\n",
    "    def __init__(self,\n",
    "                 llm, instruction_prompt,\n",
    "                 f_ground=False, f_a_rel=False,\n",
    "                 verbose=False):\n",
    "        self.llm = llm\n",
    "        assert self.llm in SNOWFLAKE_MODELS or self.llm in OPENAI_MODELS, f\"Model {self.llm} not recognized\"\n",
    "        self.instruction_prompt = instruction_prompt\n",
    "        self.f_ground = f_ground\n",
    "        self.f_a_rel = f_a_rel\n",
    "        self.verbose = verbose\n",
    "        self.embed_model = 'text-embedding-3-small'\n",
    "\n",
    "    def train(self, source_docs_df):\n",
    "        # set up vector store\n",
    "        print('Setting up vector store (for grounding)')\n",
    "        embed_model = 'text-embedding-3-small'\n",
    "        self.chroma_client = chromadb.EphemeralClient()\n",
    "        embedding_function = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=os.getenv('OPENAI_API_KEY'),\n",
    "                model_name=self.embed_model\n",
    "            )\n",
    "        self.vector_store = self.chroma_client.get_or_create_collection(name=\"source_docs\",\n",
    "                                                                        embedding_function=embedding_function)\n",
    "        ids = self.vector_store.get(include=[\"documents\"])[\"ids\"]\n",
    "        new_docs = source_docs_df[~source_docs_df['id'].astype(str).isin(ids)]\n",
    "        if len(new_docs) > 0:\n",
    "            print(f'Adding {len(new_docs)} source docs to vector store')\n",
    "            self.vector_store.add(ids = new_docs['id'].astype(str).to_list(),documents= new_docs['content'].to_list())\n",
    "\n",
    "    def render_prompt(self, suspect):\n",
    "        prompt = self.instruction_prompt\n",
    "        prompt += \"STUDENT SUBMISSION: \" + suspect\n",
    "        return [{\"role\":\"user\",\"content\": prompt}]\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        top_k = 3\n",
    "        results = self.vector_store.query(query_texts=query, n_results=top_k)\n",
    "        return [doc for sublist in results['documents'] for doc in sublist]\n",
    "\n",
    "    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=1, max=10),before=warn_on_retry)\n",
    "    def generate(self, messages):\n",
    "        if self.llm in SNOWFLAKE_MODELS:\n",
    "            response = json.loads(Complete(self.llm, messages,\n",
    "                              session=snowpark_session,\n",
    "                              options={'temperature':0, 'max_tokens':MAX_LENGTH}))\n",
    "            response_text = response['choices'][0]['messages'].strip()\n",
    "            return response_text\n",
    "        else:\n",
    "            response = openai_client.chat.completions.create(messages=messages,\n",
    "            model=self.llm,\n",
    "            temperature = 0,\n",
    "            max_tokens= MAX_LENGTH)\n",
    "            response_text = response.choices[0].message.content.strip()\n",
    "            return response_text\n",
    "\n",
    "    def classify_plagiarism(self, suspect):\n",
    "        feedback = {}\n",
    "        rendered_prompt = self.render_prompt(suspect)\n",
    "        if self.verbose: print('rendered prompt')\n",
    "        output = self.generate(rendered_prompt)\n",
    "        if self.verbose:\n",
    "            print('generated output')\n",
    "            print(output)\n",
    "        if self.f_ground:\n",
    "            if self.verbose: print('checking groundedness')\n",
    "            chunks = self.retrieve(suspect)\n",
    "            if self.verbose:\n",
    "                print('retrieved docs')\n",
    "                print(chunks)\n",
    "            g_score, g_reason = groundedness(suspect, chunks, output)\n",
    "            feedback.update({'groundedness': g_score, 'groundedness reason': g_reason['reasons']})\n",
    "        if self.f_a_rel:\n",
    "            if self.verbose: print('checking answer relevance')\n",
    "            prompt_no_context = self.render_prompt(suspect)\n",
    "            a_score, a_reason = a_relevance(prompt_no_context, output)\n",
    "            feedback.update({'answer relevance': a_score, 'answer relevance reason': (a_reason['reason'] if 'reason' in a_reason\n",
    "                                                                                         else a_reason['reasons'] if 'reasons' in a_reason\n",
    "                                                                                         else a_reason)})\n",
    "        return output, feedback\n",
    "\n",
    "\n",
    "# actual eval function\n",
    "TIMEOUT = 60 # give each question 60 seconds to complete\n",
    "\n",
    "def eval_Parametric(llm, instruction_prompt, data, model_id='', split='test', threads = 10, classifier=None, dashboard = [], verbose=False):\n",
    "\n",
    "    metadata={  # add any additional config hyperparameters below\n",
    "            'llm':llm,\n",
    "            'split': split,\n",
    "            'prompt':instruction_prompt,\n",
    "            }\n",
    "    if model_id:\n",
    "        metadata['model_id'] = model_id\n",
    "    if classifier is None:\n",
    "        plagiarism_classifier = Plagiarism_Classifier_Parametric(llm, instruction_prompt,\n",
    "                                                  f_ground=True, f_a_rel=True, verbose=verbose)\n",
    "        plagiarism_classifier.train(source_docs_df)\n",
    "    else:\n",
    "        plagiarism_classifier = classifier\n",
    "\n",
    "    if threads > 1: # multi-threaded\n",
    "        batch_size = (len(data)+threads-1) // threads\n",
    "        batches = [data.iloc[i*batch_size:(i+1)*batch_size] for i in range(threads)]\n",
    "        # split data into even batches\n",
    "\n",
    "        thread_list = []\n",
    "        for i, batch in enumerate(batches):\n",
    "            if len(batch) > 0: # do not create threads for empty batches\n",
    "                thread_list.append((threading.Thread(target=eval_Parametric,\n",
    "                                                        args=(llm, instruction_prompt, batch),\n",
    "                                                        kwargs={'split':split,\n",
    "                                                                'threads':1,\n",
    "                                                                'model_id':model_id,\n",
    "                                                                'classifier':plagiarism_classifier,\n",
    "                                                                'dashboard':dashboard,\n",
    "                                                                'verbose':verbose}),\n",
    "                                    batch)) # store results for the thread by mutating these lists\n",
    "\n",
    "                print(f\"{thread_list[-1][0].name}: {len(batch)} question{'' if len(batch) == 1 else 's'}\")\n",
    "\n",
    "        # Start every thread\n",
    "        for thread, batch in thread_list:\n",
    "            thread.start()\n",
    "        # Wait for every thread to end\n",
    "        for thread, batch in thread_list:\n",
    "            thread.join(timeout=TIMEOUT*len(batch)) # allow timeout per question.\n",
    "            if thread.is_alive():\n",
    "                print(f\"{thread.name} timed out.\")\n",
    "                continue # allow timed-out threads to run until all others have been checked\n",
    "            # print(f\"{thread.name} finished.\")\n",
    "        for thread, batch in thread_list: # final check for straggler threads\n",
    "            if thread.is_alive():\n",
    "                print(f\"FINAL CHECK - {thread.name} timed out.\")\n",
    "        print(\"All threads finished\")\n",
    "    else: # single thread\n",
    "        for i, row in tqdm(data.iterrows()):\n",
    "            dash_row = metadata.copy()\n",
    "            label, feedback = plagiarism_classifier.classify_plagiarism(row['query'])\n",
    "            dash_row.update({'query':row['query'], 'expected_response':row['expected_response'], 'LABEL':row['LABEL'],'output':label})\n",
    "            dash_row.update(feedback)\n",
    "            dashboard.append(dash_row)\n",
    "    return pd.DataFrame(dashboard)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG + Direct answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-cot prompt\n",
    "direct_prompt = \"\"\"You are a teacher's aid working to assist with grading of student submissions. To ensure academic honesty and fair grading, you need to evaluate whether student works plagiarize or not from one of the provided source texts.\n",
    "\n",
    "In this class, the teacher sorts assignments into four categories based on the level of plagiarism:\n",
    "- \"NA\": no plagiarism\n",
    "- \"verbatim\": when a student copies directly from the source text\n",
    "- \"paraphrasing\": when a student rephrases the source text\n",
    "- \"summary\": when a student summarizes the source text\n",
    "\n",
    "Respond with **only the category label, as specified above** (one of \"NA\", \"verbatim\", \"paraphrasing\", \"summary\"). DO NOT respond with any other text, whitespace, or punctuation.\n",
    "\n",
    "STUDENT SUBMISSION:\"\"\"\n",
    "\n",
    "least_brazen_direct_prompt = \"\"\"You are a teacher's aid working to assist with grading of student submissions. To ensure academic honesty and fair grading, you need to evaluate whether student works plagiarize from one of the provided source texts.\n",
    "\n",
    "In this class, the teacher sorts assignments into four categories based on the level of plagiarism:\n",
    "- \"NA\": no plagiarism. most students fall into this category.\n",
    "- \"verbatim\": when a student copies directly from the source text\n",
    "- \"paraphrasing\": when a student rephrases the source text\n",
    "- \"summary\": when a student summarizes the source text\n",
    "\n",
    "Many students do not plagiarize, so it is important to be thorough in your evaluation. If the student does make reference to one of the source texts, it is important to identify the type of reference made, as it may be benign and/or properly cited.\n",
    "**DO NOT FALSELY MARK BENIGN WORK AS PLAGIARISED.** It is better to be cautious and give the student the benefit of the doubt.\n",
    "\n",
    "In your response, immediately state your confidence as \"CONFIDENCE:\" followed by **a percentage** between 0% (not confident) and 100% (extremely confident).\n",
    "Finally, respond with \"LABEL:\", followed by **the category label, as specified above** (one of \"NA\", \"verbatim\", \"paraphrasing\", \"summary\"). DO NOT respond with any other text, whitespace, or punctuation.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "<a id='eval'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'test-dashboard.csv' in os.listdir():\n",
    "    results = pd.read_csv('test-dashboard.csv')\n",
    "else:\n",
    "    results = pd.DataFrame(columns=['model_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Heuristics - Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f833c65d6fe47f9af23b1267add09a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logistic regression, trained on BLEU and ROUGE scores to predict fine-grained plagiarism labels\n",
    "model_id = 'heuristics model - fine-grained'\n",
    "if 'heuristic_dashboard.csv' in os.listdir():\n",
    "    heuristic_dashboard = pd.read_csv('heuristic_dashboard.csv')\n",
    "else:\n",
    "    heuristic_dashboard = pd.DataFrame()\n",
    "if model_id not in results['model_id'].values:\n",
    "    if 'test' not in heuristic_dashboard['split'].values:\n",
    "    heuristic_dashboard = heuristic_eval('fine', test_heuristics, model_id=model_id, threads=1,dashboard=[])\n",
    "    heuristic_dashboard.to_csv('heuristic_dashboard.csv', index=False)\n",
    "    results = pd.concat([results, heuristic_dashboard[heuristic_dashboard['model_id'].notna()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>n</th>\n",
       "      <th>accuracy_fine</th>\n",
       "      <th>accuracy_coarse</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>heuristics model - fine-grained</td>\n",
       "      <td>122</td>\n",
       "      <td>0.877049</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model_id    n  accuracy_fine  accuracy_coarse  \\\n",
       "0  heuristics model - fine-grained  122       0.877049         0.918033   \n",
       "\n",
       "   precision    recall        f1  confidence  \n",
       "0        1.0  0.830508  0.907407         NaN  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_summary_stats(heuristic_dashboard, ['model_id'], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat([heuristic_dashboard,results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id\n",
       "heuristics model - fine-grained    122\n",
       "Zero-shot CoT                      122\n",
       "RAG + Direct Prompt                122\n",
       "RAG + CoT                          122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.to_csv('test-dashboard.csv', index=False)\n",
    "results['model_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric knowledge + CoT - Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'Zero-shot CoT'\n",
    "if 'parametric-dashboard.csv' in os.listdir():\n",
    "    old_dash = pd.read_csv('parametric-dashboard.csv')\n",
    "else:\n",
    "    old_dash = pd.DataFrame()\n",
    "results = pd.concat([results, old_dash]).drop_duplicates(subset=['model_id', 'query'])\n",
    "param_results = results[(results['model_id'] == model_id)]\n",
    "if model_id not in results['model_id'].values or param_results.shape[0] < test.shape[0]:\n",
    "    llm = 'gpt-4o-mini-2024-07-18'\n",
    "    todo = test[~test['query'].isin(param_results['query'])]\n",
    "    new_dash = eval_Parametric(llm, least_brazen_parametric_prompt, todo,\n",
    "                               model_id=model_id, split='test',threads=10,dashboard=[])\n",
    "    results = pd.concat([results, new_dash])\n",
    "    pd.concat([old_dash,new_dash]).to_csv('parametric-dashboard.csv', index=False)\n",
    "results[(results['model_id']=='Zero-shot CoT' )]['query'].value_counts().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['model_id'].value_counts()\n",
    "results.to_csv('test-dashboard.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG + Direct Answering - Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = 'RAG + Direct Prompt'\n",
    "if 'direct-dashboard.csv' in os.listdir():\n",
    "    old_dash = pd.read_csv('direct-dashboard.csv')\n",
    "else:\n",
    "    old_dash = pd.DataFrame()\n",
    "results = pd.concat([results, old_dash]).drop_duplicates(subset=['model_id', 'query'])\n",
    "direct_results = results[(results['model_id'] == model_id)]\n",
    "if model_id not in results['model_id'].values or direct_results.shape[0] < test.shape[0]:\n",
    "    embed_model = 'text-embedding-3-small'\n",
    "    top_k = 3\n",
    "    llm = 'gpt-4o-mini-2024-07-18'\n",
    "    todo = test[~test['query'].isin(direct_results['query'])].copy()\n",
    "    print(todo.shape[0])\n",
    "    new_dash = eval(embed_model, top_k, llm, least_brazen_direct_prompt, todo,\n",
    "                    model_id=model_id, split='test',threads=10,dashboard=[])\n",
    "    results = pd.concat([results, new_dash])\n",
    "    pd.concat([old_dash, new_dash]).to_csv('direct-dashboard.csv', index=False)\n",
    "results[(results['model_id']=='Zero-shot CoT' )]['query'].value_counts().unique() # check that each query is only recorded once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id\n",
       "heuristics model - fine-grained     122\n",
       "Zero-shot CoT (base model)          122\n",
       "RAG + Direct Prompt (base model)    122\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results['model_id'].value_counts())\n",
    "results.to_csv('test-dashboard.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG + CoT - Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n",
      "Setting up vector store\n",
      "Thread-62 (run): 4 questions\n",
      "Thread-63 (run): 4 questions\n",
      "Thread-64 (run): 4 questions\n",
      "Thread-65 (run): 4 questions\n",
      "Thread-66 (run): 4 questions\n",
      "Thread-67 (run): 4 questions\n",
      "Thread-68 (run): 4 questions\n",
      "Thread-69 (run): 4 questions\n",
      "Thread-70 (run): 2 questions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff9c739e5ef9490d812f424bf0dc3252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decd8b7db98d49c3a4b90d62de44767c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f85a5366234b04994eff32aeb44433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6a6f1d42f04d69b0c18be4e39add58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3eac7cbb4f483d8ec8cce8e200f584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19937410c5be451d9bbab7e9ece116f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7912fa2bc74057be6fcc31feee629e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5d3e10e19345a5bf1c649483cf6e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb8a9d1a8af44ed089889da5137094f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All threads finished\n"
     ]
    }
   ],
   "source": [
    "model_id = 'RAG + CoT'\n",
    "if 'dashboard.csv' in os.listdir():\n",
    "    old_dash = pd.read_csv('dashboard.csv')\n",
    "else:\n",
    "    old_dash = pd.DataFrame()\n",
    "results = pd.concat([results, old_dash]).drop_duplicates(subset=['model_id', 'query'])\n",
    "full_results = results[(results['model_id'] == model_id)]\n",
    "if model_id not in results['model_id'].values or full_results.shape[0] < test.shape[0]:\n",
    "    embed_model = 'text-embedding-3-small'\n",
    "    top_k = 3\n",
    "    llm = 'gpt-4o-mini-2024-07-18'\n",
    "    todo = test[~test['query'].isin(full_results['query'])].copy()\n",
    "    print(todo.shape[0])\n",
    "    new_dash = eval(embed_model, top_k, llm, least_brazen_prompt, todo.iloc[:40],\n",
    "                    model_id=model_id, split='test',threads=10,dashboard=[])\n",
    "    results = pd.concat([results, new_dash])\n",
    "    pd.concat([old_dash, new_dash]).to_csv('dashboard.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_id\n",
       "heuristics model - fine-grain    122\n",
       "Zero-shot CoT                    122\n",
       "RAG + Direct Prompt              122\n",
       "RAG + CoT                        122\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results['model_id'].value_counts())\n",
    "results.to_csv('test-dashboard.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results + Discussion\n",
    "<a id='results'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>n</th>\n",
       "      <th>context relevance</th>\n",
       "      <th>groundedness</th>\n",
       "      <th>answer relevance</th>\n",
       "      <th>accuracy_fine</th>\n",
       "      <th>accuracy_coarse</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>heuristics model - fine-grained</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.704918</td>\n",
       "      <td>91.803279</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>83.050847</td>\n",
       "      <td>90.740741</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RAG + CoT</td>\n",
       "      <td>122</td>\n",
       "      <td>85.245902</td>\n",
       "      <td>67.78871</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>83.606557</td>\n",
       "      <td>74.683544</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>85.507246</td>\n",
       "      <td>90.737705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RAG + Direct Prompt</td>\n",
       "      <td>122</td>\n",
       "      <td>86.065574</td>\n",
       "      <td>79.91453</td>\n",
       "      <td>69.672131</td>\n",
       "      <td>35.593220</td>\n",
       "      <td>77.868852</td>\n",
       "      <td>68.604651</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>81.379310</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zero-shot CoT</td>\n",
       "      <td>122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.75580</td>\n",
       "      <td>89.344262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.639344</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.694915</td>\n",
       "      <td>3.278689</td>\n",
       "      <td>87.008197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model_id    n  context relevance  groundedness  \\\n",
       "3  heuristics model - fine-grained  122                NaN           NaN   \n",
       "0                        RAG + CoT  122          85.245902      67.78871   \n",
       "1              RAG + Direct Prompt  122          86.065574      79.91453   \n",
       "2                    Zero-shot CoT  122                NaN      46.75580   \n",
       "\n",
       "   answer relevance  accuracy_fine  accuracy_coarse   precision      recall  \\\n",
       "3               NaN      87.704918        91.803279  100.000000   83.050847   \n",
       "0        100.000000      52.500000        83.606557   74.683544  100.000000   \n",
       "1         69.672131      35.593220        77.868852   68.604651  100.000000   \n",
       "2         89.344262       0.000000        51.639344   50.000000    1.694915   \n",
       "\n",
       "          f1  confidence  \n",
       "3  90.740741         NaN  \n",
       "0  85.507246   90.737705  \n",
       "1  81.379310   90.000000  \n",
       "2   3.278689   87.008197  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# overall summary results\n",
    "results_summary = get_summary_stats(results, ['model_id'], ['context relevance', 'groundedness', 'answer relevance'])\n",
    "results.to_csv('test-dashboard.csv', index=False)\n",
    "for col in results_summary.columns:\n",
    "    if results_summary[col].dtype == float and 'confidence' not in col:\n",
    "        results_summary[col] = results_summary[col]*100\n",
    "sorted_res = results_summary.sort_values('accuracy_coarse', ascending=False)\n",
    "display(sorted_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[h!]\n",
      "\\caption{Classification label performances, shown as percentages. For each row, n=122.}\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Model\\_Id & Precision & Recall & \\multicolumn{2}{r}{Accuracy} \\\\\n",
      " &  &  & Fine & Oarse \\\\\n",
      "\\hline\n",
      "heuristics model - fine-grained & 100.00 & 83.05 & 87.70 & 91.80 \\\\\n",
      "Zero-shot CoT & 50.00 & 1.69 & 0.00 & 51.64 \\\\\n",
      "RAG + Direct Prompt & 68.60 & 100.00 & 35.59 & 77.87 \\\\\n",
      "RAG + CoT & 74.68 & 100.00 & 52.50 & 83.61 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\caption{RAG Trio performances, shown as percentages. For each row, n=122.}\n",
      "\\begin{tabular}{lrrr}\n",
      "\\toprule\n",
      "Model\\_Id & Context Relevance & Groundedness & Answer Relevance \\\\\n",
      "\\hline\n",
      "Zero-shot CoT & -- & 46.76 & 89.34 \\\\\n",
      "RAG + Direct Prompt & 86.07 & 79.91 & 69.67 \\\\\n",
      "RAG + CoT & 85.25 & 67.79 & 100.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# latex tables\n",
    "formatted = results_summary[['model_id',\n",
    "                       'precision','recall','accuracy_fine', 'accuracy_coarse']].iloc[::-1]\n",
    "\n",
    "formatted.columns = pd.MultiIndex.from_tuples([(\"Accuracy\", col.strip('accuracy_').title()) if \"accuracy\" in col else (col.title(), '') for col in formatted.columns])\n",
    "\n",
    "print(formatted.to_latex(float_format=\"%.2f\",\n",
    "                         position=\"h!\",\n",
    "                        escape=True,\n",
    "                        na_rep='--',\n",
    "                        index=False,\n",
    "                        caption=\"Classification label performances, shown as percentages. For each row, n=122.\")\n",
    "                        .replace('midrule', 'hline'))\n",
    "\n",
    "formatted = (results_summary[~results_summary['model_id'].str.contains('heuristic')]\n",
    "      [['model_id','context relevance','groundedness', 'answer relevance']].iloc[::-1])\n",
    "formatted.columns = [col.title() for col in formatted.columns]\n",
    "print(formatted\n",
    "      .to_latex(float_format=\"%.2f\",\n",
    "                         position=\"h!\",\n",
    "                        escape=True,\n",
    "                        na_rep='--',\n",
    "                        index=False,\n",
    "                        caption=\"RAG Trio performances, shown as percentages. For each row, n=122.\")\n",
    "                        .replace('midrule', 'hline'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot a line graph of confidence vs. accuracy_coarse, with each point labeled with the corresponding model_id.\n",
    "fig = plt.figure(figsize=(6,4), )\n",
    "ax = fig.add_subplot()\n",
    "plt.plot(results_summary['confidence'], results_summary['accuracy_coarse'], c='darkred',linewidth=4, zorder=2)\n",
    "plt.scatter(results_summary['confidence'], results_summary['accuracy_coarse'], s=100, c='darkred',zorder=3)\n",
    "for i, txt in enumerate(results_summary['model_id']):\n",
    "    if 'Zero' in txt:\n",
    "        plt.annotate('  '+txt, (results_summary['confidence'].iloc[i], results_summary['accuracy_coarse'].iloc[i]),\n",
    "                     ha='left', va='center', fontsize=20)\n",
    "    else:\n",
    "        plt.annotate(txt+'  ', (results_summary['confidence'].iloc[i], results_summary['accuracy_coarse'].iloc[i]),\n",
    "                     ha='right', va='center', fontsize=20)\n",
    "# set size of tick labels\n",
    "plt.grid(color='lightgray', linewidth=0.5, axis='both', zorder=0)\n",
    "# ax.set_xlim((85,95))\n",
    "plt.xticks(list(range(87,92)),fontsize=20)\n",
    "# ax.set_ylim((50,90))\n",
    "plt.yticks(list(range(50,91,10)), fontsize=20)\n",
    "plt.xlabel('Confidence', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.savefig('confidence_vs_accuracy.png', dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which system performed best?\n",
    "\n",
    "![results dataframe](figures/results.png)\n",
    "\n",
    "On classification accuracy, the n-gram heuristic models were the best on this dataset.\n",
    "\n",
    "However, as a tool to empower instructors to make informed decisions (whether or not they decide to bring up an academic honesty citation), our system is much more useful than the heuristic models, as the reasoning trace from the CoT report can be used as meaningful, verifiable evidence about the student work, not just a single number. \n",
    "\n",
    "Additionally, our tool is more scalable (to larger, dynamic source corpuses), more adaptable (to different types of texts and novel modes of plagiarism), and more customizeable (to instructor preferences and plagiarism criteria)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Plagiarism_Classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plagiarism_classifier \u001b[38;5;241m=\u001b[39m \u001b[43mPlagiarism_Classifier\u001b[49m(embed_model, top_k,\n\u001b[1;32m      2\u001b[0m                                                 \u001b[38;5;66;03m#   chunk_size,\u001b[39;00m\n\u001b[1;32m      3\u001b[0m                                                   llm, least_brazen_prompt,\n\u001b[1;32m      4\u001b[0m                                                   f_ground\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, f_a_rel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, f_c_rel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m suspect_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m label, feedback \u001b[38;5;241m=\u001b[39m plagiarism_classifier\u001b[38;5;241m.\u001b[39mclassify_plagiarism(suspect_text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Plagiarism_Classifier' is not defined"
     ]
    }
   ],
   "source": [
    "plagiarism_classifier = Plagiarism_Classifier(embed_model, top_k,\n",
    "                                                #   chunk_size,\n",
    "                                                  llm, least_brazen_prompt,\n",
    "                                                  f_ground=True, f_a_rel=True, f_c_rel=True, verbose=True)\n",
    "suspect_text = input(\"What text would you like to check?\")\n",
    "report, feedback = plagiarism_classifier.classify_plagiarism(suspect_text)\n",
    "print('Plagiarism Report:')\n",
    "print(report)\n",
    "print('RAG Trio Feedback:')\n",
    "print(feedback)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs329t-hw2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
